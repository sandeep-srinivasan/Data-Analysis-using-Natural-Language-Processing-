{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import regex as re\n",
    "import string\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following class and two functions have been taken from wikipedia at https://en.wikipedia.org/wiki/Trie#Algorithms\n",
    "\n",
    "class Node():\n",
    "    def __init__(self):\n",
    "       # Note that using dictionary for children (as in this implementation) would not allow lexicographic sorting mentioned in the next section (Sorting),\n",
    "       # because ordinary dictionary would not preserve the order of the keys\n",
    "        self.children = {}  # mapping from character ==> Node\n",
    "        self.value = None\n",
    "\n",
    "def find(node, key):\n",
    "    for char in key:\n",
    "        if char in node.children:\n",
    "            node = node.children[char]\n",
    "        else:\n",
    "            return None\n",
    "    return node.value\n",
    "    \n",
    "def insert(root, string, value):\n",
    "    node = root\n",
    "    index_last_char = None\n",
    "    for index_char, char in enumerate(string):\n",
    "        if char in node.children:\n",
    "            node = node.children[char]\n",
    "        else:\n",
    "            index_last_char = index_char\n",
    "            break\n",
    "\n",
    "    # append new nodes for the remaining characters, if any\n",
    "    if index_last_char is not None: \n",
    "        for char in string[index_last_char:]:\n",
    "            node.children[char] = Node()\n",
    "            node = node.children[char]\n",
    "\n",
    "    # store value in the terminal node\n",
    "    node.value = value\n",
    "\n",
    "# The following two functions have been written by the programmers for additional purposes of the trie    \n",
    "    \n",
    "def find_multiple(node, keys):\n",
    "    # Return values for multiple Keys in the trie Node in order that keys are presented\n",
    "    holder = node\n",
    "    vals = [None]*len(keys)\n",
    "    counter = 0\n",
    "    for key in keys:\n",
    "        node = holder\n",
    "        for char in key:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "        vals[counter] = node.value\n",
    "        counter += 1\n",
    "    return vals\n",
    "\n",
    "def update(node, key, difference):\n",
    "    # Change the value which is currently stored for the Key in the trie Node by a value of Difference\n",
    "    for char in key:\n",
    "        if char in node.children:\n",
    "            node = node.children[char]\n",
    "    node.value += difference  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137, 190, 2, 3, 54, 65, 120, 513, 2, 3, 634, 25, 306, 9, 552, 7, 801, 63, 35, 29, 32, 2, 3, 3, 3987, 18, 3, 44, 163, 8, 184, 2, 12, 27, 3, 7, 135, 35, 76, 1, 628, 1, 254, 78, 65, 1, 1, 75, 15, 3, 2, 21, 3, 4, 6, 305, 7, 1, 17, 15, 192, 2448, 1, 32, 2, 3, 7, 8, 4, 6, 116, 41, 130, 4, 3, 1, 112, 1, 51, 14, 1, 84, 1, 11, 4, 1, 51, 3, 33, 1, 17, 1, 63, 8, 25, 76, 37, 28, 1, 27, 114, 67, 3, 43, 27, 2, 2, 4, 17, 21, 69, 4, 217, 1, 35, 67, 2, 6, 145, 10]\n"
     ]
    }
   ],
   "source": [
    "# the sets are a data structure which was solely used for checking results with the trie\n",
    "listtopics=set()\n",
    "listplaces=set()\n",
    "listwords = set()\n",
    "article_tries = [None]*21812\n",
    "# counts for no topics and no places in articles\n",
    "cntnotop=0 \n",
    "cntnoplc=0 \n",
    "# Trie for the different topics, locations, and count of every word present across all articles\n",
    "trieTopics = Node()\n",
    "trieLoc = Node()\n",
    "WordCount = Node()\n",
    "# csv to hold all word values per article (row)\n",
    "\n",
    "articleCount = 0\n",
    "\n",
    "for i in range(0,22):\n",
    "    # over all files\n",
    "    if(i>=10):\n",
    "        # file names differ by the #, which is double digit for i>=10\n",
    "        filename = 'reut2-0'+str(i)+'.sgm'\n",
    "    else:\n",
    "        filename = 'reut2-00'+str(i)+'.sgm'\n",
    "    path = ''+filename\n",
    "    file = open(path, 'rb')\n",
    "    data = file.read()\n",
    "    x = re.findall(r'<REUTERS(.*?)</REUTERS>', data.decode(\"windows-1252\"), re.DOTALL, overlapped=True)\n",
    "    # finds all instances of \"<REUTERS . . .\" in a given file and save them \n",
    "\n",
    "    for j in range(0,len(x)):\n",
    "        # for all articles in a file since every article starts with the REUTERS tag\n",
    "        yTopic = re.findall(r'<TOPICS>(.*?)</TOPICS>', x[j], re.DOTALL, overlapped=True)\n",
    "        # store all topics in an article since an article can have multiple topics\n",
    "        for k in range(0,len(yTopic)):\n",
    "            lt = yTopic[k]\n",
    "\n",
    "            article_topics = Node()\n",
    "            topics = re.findall(r'<D>(.*?)</D>', lt, re.DOTALL, overlapped=True)\n",
    "            # Make sure D tag does not included as part of the topic name\n",
    "            if(len(topics)==0):\n",
    "                # length is 0 when there is no topic\n",
    "                cntnotop=cntnotop+1\n",
    "            for l in topics:\n",
    "                # for every topic found in an article\n",
    "                if (find(trieTopics,l) == None):\n",
    "                    # check if the topic is already in the trie, and if not insert it with value 1\n",
    "                    insert(trieTopics, l, 1)\n",
    "                    insert(article_topics, l, 1)\n",
    "                elif (find(article_topics, l) == None):\n",
    "                    insert(article_topics, l, 1)\n",
    "                    update(trieTopics, l, 1)\n",
    "                else:\n",
    "                    # its been found already in the trie so increase the value by 1\n",
    "                    update(trieTopics, l, 1)\n",
    "                    update(article_topics, l, 1)\n",
    "                #article_topics.append(l)\n",
    "                listtopics.add(l)\n",
    "        \n",
    "        article_places = []\n",
    "        yPlace = re.findall(r'<PLACES>(.*?)</PLACES>', x[j], re.DOTALL, overlapped=True)\n",
    "        for k in range(0,len(yPlace)):\n",
    "            lt = yPlace[k]\n",
    "            places = re.findall(r'<D>(.*?)</D>', lt, re.DOTALL, overlapped=True)\n",
    "            if(len(places)==0):\n",
    "                cntnoplc=cntnoplc+1\n",
    "            for l in places:\n",
    "                if (find(trieLoc, l) == None):\n",
    "                    insert(trieLoc, l, 1)\n",
    "                else:\n",
    "                    update(trieLoc, l, 1)\n",
    "                article_places.append(l)\n",
    "                listplaces.add(l)\n",
    "\n",
    "        article_words = Node()        \n",
    "        yBody = re.findall(r'<BODY>(.*?)</BODY>', x[j], re.DOTALL, overlapped=True)\n",
    "        for b,word in enumerate(yBody):\n",
    "            # split the body into a bunch of different words\n",
    "            body = word.split()\n",
    "            body = [element.lower() for element in body] ; body            \n",
    "            for l in body:\n",
    "                if (find(WordCount, l) == None):\n",
    "                    insert(WordCount, l, 1)\n",
    "                    insert(article_words, l, 1)\n",
    "                elif (find(article_words, l) == None):\n",
    "                    insert(article_words, l, 1)\n",
    "                    update(WordCount, l, 1)\n",
    "                else:\n",
    "                    update(WordCount, l, 1)\n",
    "                    update(article_words, l, 1)\n",
    "                listwords.add(l)\n",
    "        #print (article_topics)\n",
    "        article_tries[articleCount] = [article_topics, article_places, article_words]\n",
    "        articleCount += 1\n",
    "\n",
    "        \n",
    "# end of main for loop for all files\n",
    "\n",
    "# Print statements for the distinct list of topics, distinct list of places, and counts of topic-less and/or place-less \n",
    "# articles.  Although, we used set data structures to display the different keys here, it is easy to fetch values for keys \n",
    "# using a trie displayed below each.  Usage of sets was only done as part of \"developing our domain-specific knowledge\".\n",
    "listtopics = list(listtopics)\n",
    "listplaces = list(listplaces)\n",
    "listwords = list(listwords)\n",
    "#print(listtopics)\n",
    "print(find_multiple(trieTopics, listtopics))\n",
    "#print(listplaces)\n",
    "#print(find_multiple(trieLoc, listplaces))\n",
    "#print(\"Data objects with no entries for topics: \" + str(cntnotop))\n",
    "#print(\"Data objects with no entries for places: \" + str(cntnoplc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12542\n"
     ]
    }
   ],
   "source": [
    "# Some tests for \"finds\" on the tries are shown below\n",
    "\n",
    "print (find(trieLoc, \"usa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "print(find(trieTopics, \"sugar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12542, 567]\n"
     ]
    }
   ],
   "source": [
    "print (find_multiple(trieLoc, ['usa', 'west-germany']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849\n",
      "50596\n"
     ]
    }
   ],
   "source": [
    "print (find(WordCount, 'agriculture'))\n",
    "print (find(WordCount, 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "104121\n"
     ]
    }
   ],
   "source": [
    "print (len(listtopics) ) #120\n",
    "trieVals = find_multiple(trieTopics, listtopics)\n",
    "#print (trieVals)\n",
    "#topictrie[0] = listtopics\n",
    "#topictrie[1] = trieVals\n",
    "#print (topictrie[1])\n",
    "'''with open('output_trie_topics.csv', 'w') as csvfile:\n",
    "    fieldnames = ['topic', 'value']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(listtopics)):\n",
    "        writer.writerow({'topic': topictrie[0][i], 'value': topictrie[1][i]})'''\n",
    "#np.savetxt(\"output_trei_topics.csv\", topictrie, delimiter=\",\")\n",
    "print (len(find_multiple(article_tries[0][2], listwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint (len(article_tries))\\nprint (article_tries[1][0])\\nwith open('output_article_words.csv', 'w') as csvfile:\\n    #fieldnames = ['article#', 'topics', 'places', listwords]\\n    #writer = csv.writer(csvfile)\\n    #writer.writeheader()\\n    for i in range(len(article_tries)):\\n        topicString = ''\\n        placeString = ''\\n        valueString = ''\\n        wordVals = find_multiple(article_tries[i][2], listwords)\\n        if article_tries[i] != None:\\n            for string in article_tries[i][0]:\\n                topicString +=  string + ' '\\n            for string in article_tries[i][1]:\\n                placeString +=  string + ' '\\n            for value in wordVals:\\n                valueString +=  str(value) + ', '\\n        csvfile.write(str(i) + ',' + topicString + ', ' + placeString + ', ' + valueString + '\\n')\\n    \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print (len(article_tries))\n",
    "print (article_tries[1][0])\n",
    "with open('output_article_words.csv', 'w') as csvfile:\n",
    "    #fieldnames = ['article#', 'topics', 'places', listwords]\n",
    "    #writer = csv.writer(csvfile)\n",
    "    #writer.writeheader()\n",
    "    for i in range(len(article_tries)):\n",
    "        topicString = ''\n",
    "        placeString = ''\n",
    "        valueString = ''\n",
    "        wordVals = find_multiple(article_tries[i][2], listwords)\n",
    "        if article_tries[i] != None:\n",
    "            for string in article_tries[i][0]:\n",
    "                topicString +=  string + ' '\n",
    "            for string in article_tries[i][1]:\n",
    "                placeString +=  string + ' '\n",
    "            for value in wordVals:\n",
    "                valueString +=  str(value) + ', '\n",
    "        csvfile.write(str(i) + ',' + topicString + ', ' + placeString + ', ' + valueString + '\\n')\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, myname):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1, name=myname)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape, myname):\n",
    "    initial = tf.constant(0.1, shape=shape, name=myname)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NETWORK\n",
    "\n",
    "# 1st layer\n",
    "x = tf.placeholder(tf.float32, shape=[None, 104121], name=\"x\")\n",
    "y_input = tf.placeholder(tf.float32, shape=[None, 120], name=\"y_input\")\n",
    "\n",
    "W = weight_variable([104121, 50], \"W\")\n",
    "b = bias_variable([50], \"b\")\n",
    "y_1 = tf.nn.leaky_relu(tf.add(tf.matmul(x, W), b))\n",
    "\n",
    "W2 = weight_variable([50, 120], \"W2\")\n",
    "b2 = bias_variable([120], \"b2\")\n",
    "y_test = tf.add(tf.matmul(y_1, W2), b2, name=\"out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ssd = tf.squared_difference(y_input, y_test)\n",
    "test = tf.squeeze(ssd)\n",
    "#divres = tf.div(test, ugh2)\n",
    "cross_entropy = tf.reduce_mean(ssd)  # switched ssd in for divres\n",
    "tv = tf.trainable_variables()\n",
    "grads = list(zip(tf.gradients(cross_entropy, tv), tv))\n",
    "for grad, variables in grads:\n",
    "    variable_3 = grad\n",
    "tf.summary.scalar('loss', cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cross_entropy, name=\"gradDescent\")\n",
    "# switched adam to gradientdescent and removed epsilon of e-3\n",
    "\n",
    "myind = tf.argmax(y_test,1)\n",
    "myindTrue = tf.argmax(y_input,1)\n",
    "myacc = tf.equal(myind,myindTrue)\n",
    "\n",
    "some = tf.clip_by_value(ssd, clip_value_min=1e-7, clip_value_max=1e6)  # switched ssd in for divres\n",
    "condition = tf.less(some, 1e-5)  # changed 1e-5 to 1\n",
    "correct_prediction = tf.where(condition, tf.ones_like(condition), tf.zeros_like(condition))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"acc\")\n",
    "tf.summary.scalar('acc', accuracy)\n",
    "merge = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "tf.add_to_collection(\"optimizer\", train_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 120)\n",
      "step 0, training accuracy 0\n",
      "step 0, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[-28.004955   -36.05069    -39.54859     54.315006   -43.037235\n",
      "   -0.62411064  41.20946    -13.107423     6.4129944   58.424145\n",
      "  -28.280302     8.317188   -48.961704    76.446884    17.745432\n",
      "   18.456127    11.046552   -22.714123    47.311596   -17.628038\n",
      "  -30.585367   -26.024021    -9.144962   -35.689087   -16.983421\n",
      "   19.775702   -28.402918   -55.63756    -64.623436   -45.54339\n",
      "  -21.64617    -34.45556     -5.0017285   15.071354   -29.257824\n",
      "   43.0074      24.334518   -12.5821705   44.428917     9.7956295\n",
      "   44.53062      5.8382545   35.630676   -37.30334     54.442898\n",
      "   38.77463     -4.5728207  -27.08182      4.8756275    6.895401\n",
      "  -22.54658     19.933401   -15.4204445   -6.1629744   27.597912\n",
      "   -5.2793875    8.19855     31.800007   -59.23969      7.4925656\n",
      "   -6.5478363   10.117939   -27.3233     -17.006014    -1.2787085\n",
      "   -0.21877614  22.83069    -34.624634   -42.217117   -17.692196\n",
      "   53.274742    -4.31864     15.047922   -13.281285    -8.058862\n",
      "   -8.052779   -17.03282     22.57551      4.9958816   37.468063\n",
      "  -24.585497    12.612712    -3.0827668   -7.9798074  -18.976707\n",
      "  -18.472012     1.4032787   31.620878   -14.62163    -22.58073\n",
      "  -36.31663    -45.927177    30.521841    -2.9133518  -14.601322\n",
      "  -14.315969   -36.39462     15.025185   -14.826168    44.090847\n",
      "   42.164223   -41.833076     3.4628272   11.171903    18.697426\n",
      "   35.16645    -48.703083    20.38819     -5.8642545  -13.003553\n",
      "   57.305374    11.688091   -46.130188    63.484623   -13.843942\n",
      "   21.666557    43.144394     5.6575537  -15.568185    10.962851  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "896.50806\n",
      "step 100, training accuracy 0\n",
      "step 100, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[-6.3948011e+00 -2.8760319e+01 -4.7767464e+01  2.0687490e+01\n",
      "  -3.6843277e+01 -2.0849228e+01  2.1233135e+01 -2.2180403e+01\n",
      "  -4.8414531e+00  2.9560520e+01 -6.6175175e+00  1.5390382e+01\n",
      "  -1.8276587e+01  6.0010380e+01 -6.4088850e+00  1.4075238e+01\n",
      "   1.6243011e-02 -1.1726974e+01  1.4875545e+01  2.0766733e+00\n",
      "  -2.7144646e+01 -2.8430374e+01 -8.3743773e+00 -1.8994314e+01\n",
      "   2.7098172e+00  2.8817410e+01 -1.1468445e+01 -1.8821589e+01\n",
      "  -4.4390999e+01 -1.4123718e+01 -8.9253750e+00 -2.0218971e+01\n",
      "  -2.5835645e+00  9.5481243e+00 -7.7668095e+00  2.8847233e+01\n",
      "   9.7654219e+00 -1.4774851e+01  2.9393442e+01 -2.3400626e+00\n",
      "   2.5177078e+01  9.5008993e+00  1.8703217e+01 -5.1867420e+01\n",
      "   3.5178356e+01  1.3486350e+01 -3.3940864e-01 -2.2691259e+01\n",
      "   3.2933475e+01 -7.4097385e+00 -7.7212224e+00  1.5967807e+01\n",
      "  -7.8849421e+00 -1.1196250e+01  1.1021777e+01 -1.0985237e+00\n",
      "  -6.2264524e+00  2.4631729e+01 -3.9523575e+01  7.2949066e+00\n",
      "  -4.5786357e+00  2.9398985e+01 -3.6335510e+01 -2.2511719e+01\n",
      "   1.4621217e+01  5.7831800e-01  8.5843992e+00 -2.1587893e+01\n",
      "  -3.5194210e+01  2.1531866e+00  2.7273312e+01 -6.5096221e+00\n",
      "  -7.1707392e-01 -1.7287854e+00 -7.1137148e-01 -2.2394709e+01\n",
      "  -3.4431674e+00 -1.4411110e+01 -2.2060556e+00 -5.6712079e-01\n",
      "  -5.7350197e+00 -8.3032007e+00 -1.6335454e+00 -9.8743277e+00\n",
      "  -1.8577486e+01 -1.7084339e+01  2.2802370e+01  3.1861805e+01\n",
      "   7.3832912e+00 -3.3943503e+00 -5.2373920e+01 -6.3265996e+00\n",
      "   2.0215567e+01 -1.2770339e+01 -2.0344645e+01 -1.9684015e+01\n",
      "  -3.3491623e+01  3.0873466e-01  1.1800525e+01  3.1414288e+01\n",
      "   1.5552791e+01 -1.7893524e+01  8.6335192e+00  7.3033314e+00\n",
      "  -2.3968685e+00 -4.3654332e+00 -3.2933640e+01  8.8682013e+00\n",
      "   3.5337987e+00  3.9321780e+00  5.8075325e+01 -7.7789412e+00\n",
      "  -3.1451054e+01  4.4362713e+01 -1.0092629e+01  9.2689228e+00\n",
      "   2.6446070e+01 -4.3055301e+00  9.6755524e+00  1.5261569e+01]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "453.53723\n",
      "step 200, training accuracy 0\n",
      "step 200, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[-6.60569906e+00 -3.08671551e+01 -4.79277077e+01  2.08730850e+01\n",
      "  -3.80931358e+01 -1.99393120e+01  2.12952118e+01 -2.13133011e+01\n",
      "  -5.75912905e+00  2.97072601e+01 -7.05666542e+00  1.35561438e+01\n",
      "  -1.80122547e+01  6.33496361e+01 -7.07844067e+00  1.50201139e+01\n",
      "  -1.73461723e+00 -1.40358410e+01  1.49238005e+01  1.09727335e+00\n",
      "  -2.79969864e+01 -2.76605816e+01 -8.80665588e+00 -2.04268589e+01\n",
      "   2.94737697e+00  2.98249397e+01 -1.26527758e+01 -1.77021217e+01\n",
      "  -4.51142998e+01 -1.56022348e+01 -1.04302387e+01 -2.02088661e+01\n",
      "  -2.87921786e+00  9.50818729e+00 -7.16205454e+00  2.81867752e+01\n",
      "   1.09671240e+01 -1.53628855e+01  3.30598793e+01 -2.89062238e+00\n",
      "   2.53256645e+01  9.88147926e+00  1.92194786e+01 -5.29596481e+01\n",
      "   3.56554108e+01  1.45344648e+01 -3.85203362e-01 -2.35465660e+01\n",
      "   3.41956902e+01 -7.14925098e+00 -8.31431770e+00  1.55008755e+01\n",
      "  -7.56678915e+00 -1.13585844e+01  1.06587591e+01 -1.12076610e-01\n",
      "  -5.08483887e+00  2.56513634e+01 -4.20819626e+01  8.29919147e+00\n",
      "  -5.71329403e+00  2.99300480e+01 -3.76585922e+01 -2.32658997e+01\n",
      "   1.59324217e+01  1.33619756e-02  7.96893311e+00 -2.46143799e+01\n",
      "  -3.53418427e+01  1.35727441e+00  2.74780254e+01 -7.01434851e+00\n",
      "  -2.00395679e+00 -2.38481545e+00 -1.29672503e+00 -2.20121689e+01\n",
      "  -3.34073901e+00 -1.68246803e+01 -1.31963956e+00  1.66033953e-02\n",
      "  -6.80146360e+00 -9.44085884e+00 -3.28035057e-01 -8.64794350e+00\n",
      "  -2.01610909e+01 -1.80198975e+01  2.34553547e+01  3.34160080e+01\n",
      "   7.38409090e+00 -1.90990329e+00 -5.33625832e+01 -8.53768539e+00\n",
      "   2.00957851e+01 -1.27404613e+01 -2.17791424e+01 -2.00228920e+01\n",
      "  -3.38765602e+01  1.25737667e+00  1.19967985e+01  3.21120186e+01\n",
      "   1.66809311e+01 -1.88119240e+01  8.82071400e+00  7.34109116e+00\n",
      "  -2.04785776e+00 -6.78566694e+00 -3.46777267e+01  9.32651615e+00\n",
      "   4.95368814e+00  3.58361435e+00  5.84691048e+01 -7.95170975e+00\n",
      "  -3.38976402e+01  4.61940842e+01 -1.16439943e+01  1.21413002e+01\n",
      "   2.69040546e+01 -4.21343994e+00  9.88233089e+00  1.48636112e+01]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "481.5316\n",
      "step 300, training accuracy 0\n",
      "step 300, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[ -6.9775047  -31.41172    -48.452023    21.084698   -38.7537\n",
      "  -19.761522    21.72828    -21.192314    -6.262913    29.957897\n",
      "   -7.799782    12.649629   -17.855473    64.566765    -6.9635143\n",
      "   15.804998    -2.2059262  -14.910826    14.937489     0.58852166\n",
      "  -28.266048   -27.503386    -8.643624   -20.806974     3.0871634\n",
      "   30.314724   -13.293333   -17.269089   -45.68308    -16.612743\n",
      "  -11.098712   -20.34603     -3.0459437    9.783084    -7.087944\n",
      "   27.608946    11.193174   -15.358554    34.496014    -3.3322546\n",
      "   25.619276     9.828446    19.531027   -53.207973    35.693935\n",
      "   15.282029    -0.27362096 -23.883633    34.725147    -6.824453\n",
      "   -8.356975    15.321269    -7.4898596  -11.620671    10.672107\n",
      "    0.4691074   -4.4138002   26.310122   -43.13264      8.700239\n",
      "   -6.093741    29.987286   -38.213703   -23.211754    16.605436\n",
      "   -0.29046574   7.6869     -25.81651    -35.469913     1.2058853\n",
      "   27.705467    -7.1903305   -2.3573031   -2.8702853   -1.3676602\n",
      "  -21.656837    -3.2558088  -17.690388    -1.0769222    0.31877574\n",
      "   -7.3741336   -9.84103      0.10080756  -8.216443   -20.74623\n",
      "  -18.107393    23.396677    34.066814     7.351078    -1.5074108\n",
      "  -53.880016    -9.334847    20.22342    -12.823413   -22.11245\n",
      "  -20.337194   -33.90111      1.5669708   12.102623    33.008713\n",
      "   17.30317    -19.298872     9.32008      7.642309    -1.6784155\n",
      "   -7.727331   -35.184788     9.483241     5.6815205    3.3107827\n",
      "   58.508797    -8.106507   -34.714104    47.041195   -12.458825\n",
      "   13.30629     26.889877    -3.914093     9.731604    14.872077  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "494.43372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 400, training accuracy 0\n",
      "step 400, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[ -7.217411   -31.770046   -48.865845    21.26835    -39.048904\n",
      "  -19.63005     22.07645    -21.323116    -6.493018    30.175007\n",
      "   -8.385236    12.06858    -17.73897     65.24854     -6.9264855\n",
      "   16.513475    -2.4067469  -15.365644    15.031938     0.24078074\n",
      "  -28.38701    -27.424725    -8.514429   -21.057318     3.0856087\n",
      "   30.613695   -13.6502     -17.020988   -45.930702   -17.382935\n",
      "  -11.496711   -20.389402    -3.2066057   10.028146    -7.118074\n",
      "   27.165688    11.286044   -15.332037    35.192413    -3.6082878\n",
      "   25.732311     9.787906    19.795368   -53.35007     35.518448\n",
      "   15.681291    -0.11028124 -24.042841    35.13948     -6.65495\n",
      "   -8.243175    15.205106    -7.330502   -11.925693    10.849756\n",
      "    0.90104854  -4.071379    26.741333   -43.718796     8.950721\n",
      "   -6.294257    30.003279   -38.581196   -23.061457    17.012436\n",
      "   -0.408923     7.6027756  -26.333916   -35.552067     1.2840751\n",
      "   27.963888    -7.077669    -2.5427399   -3.1706307   -1.2824886\n",
      "  -21.37797     -3.2013357  -18.08968     -1.1406956    0.48442212\n",
      "   -7.6317782  -10.191006     0.23337966  -7.9571857  -21.099154\n",
      "  -18.110218    23.270422    34.449585     7.345986    -1.4534514\n",
      "  -54.227848    -9.634072    20.32652    -12.844121   -22.177284\n",
      "  -20.633057   -33.96296      1.6995431   12.213968    33.640987\n",
      "   17.556538   -19.528494     9.729937     7.937395    -1.5271881\n",
      "   -8.116804   -35.378716     9.616323     6.1704707    3.1064465\n",
      "   58.51359     -8.346915   -35.166653    47.44777    -13.147278\n",
      "   14.038017    26.710299    -3.6190438    9.559244    15.187077  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "502.08777\n",
      "step 500, training accuracy 0\n",
      "step 500, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[-7.4091606e+00 -3.2086433e+01 -4.9141983e+01  2.1446671e+01\n",
      "  -3.9237591e+01 -1.9569839e+01  2.2381104e+01 -2.1447710e+01\n",
      "  -6.5993762e+00  3.0368015e+01 -8.8049459e+00  1.1724101e+01\n",
      "  -1.7636587e+01  6.5696533e+01 -6.9472427e+00  1.7076029e+01\n",
      "  -2.4993789e+00 -1.5705489e+01  1.5308252e+01  1.7719403e-02\n",
      "  -2.8535282e+01 -2.7318506e+01 -8.4625311e+00 -2.1274208e+01\n",
      "   3.0464635e+00  3.0762598e+01 -1.3840057e+01 -1.6863081e+01\n",
      "  -4.6054222e+01 -1.7954086e+01 -1.1786711e+01 -2.0421104e+01\n",
      "  -3.3584175e+00  1.0183748e+01 -7.1434460e+00  2.6861614e+01\n",
      "   1.1340703e+01 -1.5315362e+01  3.5534824e+01 -3.7283103e+00\n",
      "   2.5885994e+01  9.7165947e+00  2.0005028e+01 -5.3456055e+01\n",
      "   3.5386635e+01  1.5877282e+01 -6.1883375e-02 -2.4153196e+01\n",
      "   3.5405090e+01 -6.5433769e+00 -8.1254969e+00  1.5134043e+01\n",
      "  -7.0933518e+00 -1.2140111e+01  1.1102114e+01  1.1896671e+00\n",
      "  -3.8248813e+00  2.6977667e+01 -4.4162369e+01  9.1628857e+00\n",
      "  -6.4096050e+00  2.9975697e+01 -3.8890514e+01 -2.2878311e+01\n",
      "   1.7255920e+01 -4.7978926e-01  7.5750360e+00 -2.6575497e+01\n",
      "  -3.5622169e+01  1.4572673e+00  2.8252228e+01 -6.9432569e+00\n",
      "  -2.6177874e+00 -3.3398812e+00 -1.2364713e+00 -2.1112465e+01\n",
      "  -3.2599604e+00 -1.8268486e+01 -1.2719342e+00  6.0856926e-01\n",
      "  -7.6891465e+00 -1.0487663e+01  3.2127962e-01 -7.8246260e+00\n",
      "  -2.1364895e+01 -1.8131639e+01  2.3151384e+01  3.4729404e+01\n",
      "   7.3126154e+00 -1.4452105e+00 -5.4489143e+01 -9.7411737e+00\n",
      "   2.0419889e+01 -1.2866136e+01 -2.2126684e+01 -2.0934923e+01\n",
      "  -3.3982491e+01  1.7776654e+00  1.2222724e+01  3.4102318e+01\n",
      "   1.7758142e+01 -1.9635674e+01  1.0007104e+01  8.2094889e+00\n",
      "  -1.4799401e+00 -8.3316956e+00 -3.5423164e+01  9.6721430e+00\n",
      "   6.4521990e+00  2.9889889e+00  5.8511482e+01 -8.5376596e+00\n",
      "  -3.5440815e+01  4.7648972e+01 -1.3692469e+01  1.4550136e+01\n",
      "   2.6530628e+01 -3.3084919e+00  9.4644718e+00  1.5564210e+01]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "507.35855\n",
      "step 600, training accuracy 0\n",
      "step 600, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[ -7.533903   -32.316914   -49.357533    21.578955   -39.318314\n",
      "  -19.571865    22.616034   -21.61543     -6.6681886   30.583185\n",
      "   -9.116933    11.477555   -17.570526    65.90366     -6.955397\n",
      "   17.48723     -2.5066054  -15.958095    15.564819    -0.10427105\n",
      "  -28.715103   -27.17904     -8.436855   -21.4302       3.0040257\n",
      "   30.796247   -13.927976   -16.725653   -46.076023   -18.354362\n",
      "  -11.99887    -20.381618    -3.5026195   10.314174    -7.1896677\n",
      "   26.640947    11.33374    -15.231463    35.700077    -3.7411416\n",
      "   25.988224     9.682763    20.218348   -53.651646    35.275864\n",
      "   15.998899    -0.12540445 -24.206736    35.583076    -6.4799848\n",
      "   -8.078024    15.1192465   -6.872154   -12.331005    11.30054\n",
      "    1.407497    -3.6798003   27.131561   -44.517384     9.396979\n",
      "   -6.4840894   30.029484   -39.127647   -22.73801     17.437408\n",
      "   -0.57989717   7.5763173  -26.774984   -35.654305     1.6544269\n",
      "   28.538715    -6.7817683   -2.659247    -3.4536147   -1.2249627\n",
      "  -20.915531    -3.333317   -18.380188    -1.418413     0.67169577\n",
      "   -7.66462    -10.7480345    0.34210986  -7.8247075  -21.55945\n",
      "  -18.1692      23.098303    35.061317     7.295571    -1.4142679\n",
      "  -54.639763    -9.745528    20.515593   -12.873119   -21.994434\n",
      "  -21.22843    -34.031242     1.7892268   12.228669    34.48615\n",
      "   17.830917   -19.743216    10.20417      8.437036    -1.4797683\n",
      "   -8.449597   -35.384094     9.732077     6.625865     2.9864092\n",
      "   58.483997    -8.667227   -35.579533    47.81358    -14.065743\n",
      "   14.890258    26.331919    -3.017745     9.446174    15.994329  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "511.21924\n",
      "step 700, training accuracy 0\n",
      "step 700, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[ -7.6079755  -32.469025   -49.55924     21.720984   -39.415257\n",
      "  -19.592363    22.792067   -21.748604    -6.707913    30.77268\n",
      "   -9.361228    11.330771   -17.496075    65.997574    -6.919416\n",
      "   17.8211      -2.4910254  -16.115347    15.865521    -0.23456563\n",
      "  -28.836714   -27.057133    -8.433541   -21.56972      3.000535\n",
      "   30.81121    -13.93071    -16.625025   -46.181835   -18.64645\n",
      "  -12.14808    -20.376331    -3.5963514   10.382231    -7.219586\n",
      "   26.450327    11.332294   -15.173887    35.813114    -3.7087352\n",
      "   26.079567     9.622916    20.35978    -53.761715    35.214573\n",
      "   16.095016    -0.1548042  -24.24925     35.720848    -6.400059\n",
      "   -8.008804    15.058371    -6.6931887  -12.489748    11.467935\n",
      "    1.5947117   -3.6153471   27.226604   -44.79889      9.574078\n",
      "   -6.5198827   30.066065   -39.30419    -22.606781    17.550592\n",
      "   -0.69217914   7.5994306  -26.890747   -35.724075     1.8259563\n",
      "   28.772097    -6.65679     -2.667626    -3.5496724   -1.1703401\n",
      "  -20.745737    -3.4256392  -18.473286    -1.5449245    0.6955007\n",
      "   -7.6211896  -10.932276     0.33484238  -7.8746395  -21.726677\n",
      "  -18.172789    23.062857    35.29335      7.267591    -1.4276196\n",
      "  -54.740467    -9.746842    20.56447    -12.886997   -21.850254\n",
      "  -21.479822   -34.034172     1.8324405   12.204892    34.82286\n",
      "   17.83018    -19.802782    10.311782     8.648145    -1.4671646\n",
      "   -8.553788   -35.340084     9.809875     6.769203     2.9953356\n",
      "   58.538578    -8.769349   -35.67136     47.92786    -14.347288\n",
      "   15.105996    26.166443    -2.761694     9.399881    16.342644  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "514.1775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 800, training accuracy 0\n",
      "step 800, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[ -7.6396     -32.584488   -49.69337     21.857725   -39.489616\n",
      "  -19.597107    22.944754   -21.842455    -6.734906    30.933182\n",
      "   -9.570794    11.18803    -17.468567    66.07489     -6.8890224\n",
      "   18.126411    -2.5111558  -16.197018    16.159956    -0.35115814\n",
      "  -28.94453    -26.947578    -8.463364   -21.691105     3.0249786\n",
      "   30.826418   -13.952406   -16.520657   -46.274353   -18.864311\n",
      "  -12.264576   -20.37561     -3.6793163   10.436292    -7.263895\n",
      "   26.302738    11.351015   -15.123293    35.897686    -3.6609516\n",
      "   26.15624      9.579005    20.455149   -53.813343    35.144325\n",
      "   16.176174    -0.15431778 -24.268278    35.853283    -6.338696\n",
      "   -7.927994    14.972657    -6.532302   -12.635058    11.592648\n",
      "    1.7636684   -3.583511    27.267887   -45.026        9.707953\n",
      "   -6.5417585   30.104929   -39.421803   -22.480173    17.642569\n",
      "   -0.76684946   7.6362557  -26.963339   -35.790092     2.005956\n",
      "   28.9512      -6.590815    -2.6611366   -3.610227    -1.1326826\n",
      "  -20.593296    -3.4956636  -18.537836    -1.6482629    0.7057761\n",
      "   -7.5817065  -11.097037     0.3202902   -7.9021897  -21.838053\n",
      "  -18.179459    23.047663    35.465843     7.213557    -1.4418763\n",
      "  -54.799778    -9.738282    20.589933   -12.886223   -21.734926\n",
      "  -21.645706   -34.02329      1.8452497   12.189188    35.086636\n",
      "   17.817667   -19.849081    10.392369     8.817037    -1.4653255\n",
      "   -8.630223   -35.30315      9.890731     6.8540025    3.0021286\n",
      "   58.57845     -8.8706255  -35.720486    48.016766   -14.587847\n",
      "   15.278251    26.038702    -2.5553174    9.344009    16.624971  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "516.40466\n",
      "step 900, training accuracy 0\n",
      "step 900, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[ -7.66097    -32.666653   -49.77992     21.980562   -39.52154\n",
      "  -19.59035     23.044823   -21.919611    -6.7720337   31.060562\n",
      "   -9.731535    11.090521   -17.45289     66.18791     -6.875319\n",
      "   18.38525     -2.5280375  -16.249344    16.414312    -0.44345498\n",
      "  -29.05141    -26.852345    -8.504199   -21.823082     3.036419\n",
      "   30.836409   -13.972608   -16.473972   -46.32986    -19.049341\n",
      "  -12.338234   -20.37032     -3.75853     10.508591    -7.295683\n",
      "   26.177979    11.403603   -15.101529    35.94022     -3.5628936\n",
      "   26.241776     9.583955    20.541853   -53.85153     35.079704\n",
      "   16.220573    -0.14947906 -24.268969    35.93835     -6.30457\n",
      "   -7.8514256   14.897685    -6.395998   -12.735609    11.714878\n",
      "    1.9205829   -3.5643065   27.276628   -45.224003     9.817989\n",
      "   -6.5377765   30.130016   -39.48582    -22.367828    17.70419\n",
      "   -0.8256542    7.675797   -27.029013   -35.840015     2.1515508\n",
      "   29.077118    -6.5377164   -2.6758974   -3.6202      -1.1180131\n",
      "  -20.462164    -3.5699413  -18.590927    -1.7440667    0.72372603\n",
      "   -7.555122   -11.236984     0.33373842  -7.9347343  -21.9308\n",
      "  -18.196571    23.037243    35.587772     7.168168    -1.47506\n",
      "  -54.84667     -9.720625    20.561705   -12.8742     -21.63634\n",
      "  -21.740387   -33.998497     1.8580023   12.152308    35.29831\n",
      "   17.82267    -19.86642     10.449382     8.966352    -1.4691335\n",
      "   -8.643462   -35.274883     9.980556     6.9054704    2.982642\n",
      "   58.61745     -8.948696   -35.766563    48.055515   -14.815719\n",
      "   15.459798    25.92858     -2.3694751    9.282893    16.86777   ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "518.13055\n",
      "step 1000, training accuracy 0\n",
      "step 1000, training accuracy 0\n",
      "ind 13, index true 38\n",
      "validation accuracy 0\n",
      "[[ -7.678428   -32.721287   -49.886547    22.109457   -39.585274\n",
      "  -19.603323    23.149427   -21.996803    -6.771774    31.13489\n",
      "   -9.880517    11.025816   -17.416431    66.27302     -6.8565364\n",
      "   18.608318    -2.53764    -16.283134    16.647875    -0.5293029\n",
      "  -29.13856    -26.802076    -8.53137    -21.935354     3.0574167\n",
      "   30.848537   -13.96712    -16.455929   -46.388493   -19.207817\n",
      "  -12.403405   -20.362062    -3.8242424   10.587883    -7.3264484\n",
      "   26.062778    11.4473715  -15.091975    35.957836    -3.471917\n",
      "   26.325964     9.569342    20.63458    -53.878845    35.044518\n",
      "   16.256035    -0.13764027 -24.278296    36.01441     -6.269478\n",
      "   -7.747807    14.857475    -6.288224   -12.814844    11.830064\n",
      "    2.0503387   -3.566933    27.301033   -45.39171      9.897137\n",
      "   -6.519919    30.152409   -39.54712    -22.292412    17.739643\n",
      "   -0.89057577   7.731068   -27.05891    -35.916782     2.2856936\n",
      "   29.1701      -6.4797974   -2.6705072   -3.6355934   -1.0873497\n",
      "  -20.352287    -3.623654   -18.626646    -1.8183137    0.7217077\n",
      "   -7.5213     -11.345146     0.32426763  -7.975267   -22.026964\n",
      "  -18.182617    23.032494    35.694923     7.1493      -1.5224904\n",
      "  -54.912735    -9.706658    20.539726   -12.864586   -21.57007\n",
      "  -21.829353   -33.978035     1.8785478   12.122296    35.47796\n",
      "   17.841358   -19.858826    10.502351     9.10701     -1.4773109\n",
      "   -8.646349   -35.246094    10.054097     6.9453073    2.9655666\n",
      "   58.65777     -9.025993   -35.780376    48.090626   -15.014627\n",
      "   15.6081705   25.86204     -2.203451     9.227066    17.054766  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "519.72815\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    # train_writer = tf.summary.FileWriter('beginner', sess.graph)\n",
    "    train_writer2 = tf.summary.FileWriter('validation', sess.graph)\n",
    "    # sess.run()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # example input: find_multiple(article_tries[0][2], listwords)\n",
    "    # input setup\n",
    "    train_size = 5  # 1234\n",
    "    test_size = 1\n",
    "    batch_size = 10\n",
    "    i = 0\n",
    "    yans = [None] * train_size\n",
    "    xans = [None] * train_size\n",
    "    xans2 = [None] * test_size  # 26\n",
    "    yans2 = [None] * test_size\n",
    "    epochs = 0\n",
    "    count = 0\n",
    "    count2 = 0\n",
    "    loss = 1e10\n",
    "    while i < 6:  \n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        mytemp = find_multiple(article_tries[i][2], listwords)\n",
    "        mytemp = [j if (j != None) else 0 for j in mytemp]\n",
    "        mytemp2 = find_multiple(article_tries[i][0], listtopics)\n",
    "        mytemp2 = [j if (j != None) else 0 for j in mytemp2]\n",
    "        #print (mytemp)\n",
    "        for j in range(len(mytemp)):\n",
    "            temp.append(float(mytemp[j]))\n",
    "        for j in range (len(mytemp2)):\n",
    "            temp2.append(float(mytemp2[j]))\n",
    "        if i % 6  != 0:\n",
    "            xans[count] = temp\n",
    "            yans[count] = temp2\n",
    "            count += 1\n",
    "        else:\n",
    "            xans2[count2] = temp\n",
    "            yans2[count2] = temp2\n",
    "            count2 += 1\n",
    "        i +=1\n",
    "    yans = np.array(yans, dtype=np.float64)\n",
    "    yans2 = np.array(yans2, dtype=np.float64)\n",
    "   # yans2[0] = np.array([i for i in range(120)], dtype=np.float)\n",
    "    print (yans2.shape)\n",
    "    while epochs < 50000:\n",
    "            [summary2, acc, res] = sess.run([merge, accuracy, y_test], feed_dict={x: xans2, y_input: yans2})\n",
    "            train_writer2.add_summary(summary2, epochs)\n",
    "            if epochs % 100 == 0:\n",
    "                [summaryOut, train_accuracy, something, true_val, c, myacc2, ind, ind2, yin] = sess.run([merge, accuracy, y_test, y_input,\n",
    "                                            cross_entropy, myacc, myind, myindTrue, y_input], feed_dict={x: xans2, y_input: yans2})\n",
    "                if c < loss:\n",
    "                  saver.save(sess, './my_test_model', global_step=epochs)\n",
    "                  #np.savetxt(\"output_fourier_check.csv\", true_val, delimiter=\",\")\n",
    "                  loss = c\n",
    "                a = abs(something - true_val)\n",
    "                numpy_accuracy = (a <= 1e-5).mean()   # changed 1e-5 to 1\n",
    "                try:\n",
    "                    # print (v3)\n",
    "                    print('step %d, training accuracy %g' % (epochs, train_accuracy))\n",
    "                    print('step %d, training accuracy %g' % (epochs, numpy_accuracy))\n",
    "                    #print('step %d, idk accuracy %g' % (epochs, myacc2))\n",
    "                    print('ind %d, index true %g' % (ind, ind2))\n",
    "                    print('validation accuracy %g' % acc)\n",
    "                    print (something)\n",
    "                    print(yin)\n",
    "                    print (c)\n",
    "                except OSError as e:\n",
    "                    pass\n",
    "            train_step.run(feed_dict={x: xans, y_input: yans})\n",
    "            epochs += 1\n",
    "    # print (something[0])\n",
    "    #[acc, res] = sess.run([accuracy, y_test], feed_dict={x: xans2, y: yans2})\n",
    "    #np.savetxt(\"output_fourier9.csv\", res, delimiter=\",\")\n",
    "    #print('validation accuracy %g' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listtopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
