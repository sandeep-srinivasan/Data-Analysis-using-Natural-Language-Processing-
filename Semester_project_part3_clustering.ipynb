{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import regex as re\n",
    "import string\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following class and two functions have been taken from wikipedia at https://en.wikipedia.org/wiki/Trie#Algorithms\n",
    "\n",
    "class Node():\n",
    "    def __init__(self):\n",
    "       # Note that using dictionary for children (as in this implementation) would not allow lexicographic sorting mentioned in the next section (Sorting),\n",
    "       # because ordinary dictionary would not preserve the order of the keys\n",
    "        self.children = {}  # mapping from character ==> Node\n",
    "        self.value = None\n",
    "\n",
    "def find(node, key):\n",
    "    for char in key:\n",
    "        if char in node.children:\n",
    "            node = node.children[char]\n",
    "        else:\n",
    "            return None\n",
    "    return node.value\n",
    "    \n",
    "def insert(root, string, value):\n",
    "    node = root\n",
    "    index_last_char = None\n",
    "    for index_char, char in enumerate(string):\n",
    "        if char in node.children:\n",
    "            node = node.children[char]\n",
    "        else:\n",
    "            index_last_char = index_char\n",
    "            break\n",
    "\n",
    "            # append new nodes for the remaining characters, if any\n",
    "    if index_last_char is not None: \n",
    "        for char in string[index_last_char:]:\n",
    "            node.children[char] = Node()\n",
    "            node = node.children[char]\n",
    "\n",
    "    # store value in the terminal node\n",
    "    node.value = value\n",
    "\n",
    "# The following two functions have been written by the programmers for additional purposes of the trie    \n",
    "    \n",
    "def find_multiple(node, keys):\n",
    "    # Return values for multiple Keys in the trie Node in order that keys are presented\n",
    "    holder = node\n",
    "    vals = [None]*len(keys)\n",
    "    counter = 0\n",
    "    for key in keys:\n",
    "        node = holder\n",
    "        for char in key:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "        vals[counter] = node.value\n",
    "        counter += 1\n",
    "    return vals\n",
    "\n",
    "def update(node, key, difference):\n",
    "    # Change the value which is currently stored for the Key in the trie Node by a value of Difference\n",
    "    for char in key:\n",
    "        if char in node.children:\n",
    "            node = node.children[char]\n",
    "    node.value += difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sets are a data structure which was solely used for checking results with the trie\n",
    "listtopics=set()\n",
    "listplaces=set()\n",
    "listwords = set()\n",
    "article_tries = [None]*21812\n",
    "# counts for no topics and no places in articles\n",
    "cntnotop=0 \n",
    "cntnoplc=0 \n",
    "# Trie for the different topics, locations, and count of every word present across all articles\n",
    "trieTopics = Node()\n",
    "trieLoc = Node()\n",
    "WordCount = Node()\n",
    "# csv to hold all word values per article (row)\n",
    "\n",
    "articleCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(0,22):\n",
    "    # over all files\n",
    "    if(i>=10):\n",
    "        # file names differ by the #, which is double digit for i>=10\n",
    "        filename = 'reut2-0'+str(i)+'.sgm'\n",
    "    else:\n",
    "        filename = 'reut2-00'+str(i)+'.sgm'\n",
    "    path = 'I:\\\\Users\\\\Sandeep\\\\Desktop\\\\Folder\\\\Data Mining Project\\\\Github repository\\\\Data Mining project\\\\' + filename\n",
    "    file = open(path, 'rb')\n",
    "    data = file.read()\n",
    "    x = re.findall(r'<REUTERS(.*?)</REUTERS>', data.decode(\"windows-1252\"), re.DOTALL, overlapped=True)\n",
    "    # finds all instances of \"<REUTERS . . .\" in a given file and save them \n",
    "    \n",
    "    for j in range(0,len(x)):\n",
    "        # for all articles in a file since every article starts with the REUTERS tag\n",
    "        yTopic = re.findall(r'<TOPICS>(.*?)</TOPICS>', x[j], re.DOTALL, overlapped=True)\n",
    "        # store all topics in an article since an article can have multiple topics\n",
    "        \n",
    "        for k in range(0,len(yTopic)):\n",
    "            lt = yTopic[k]\n",
    "\n",
    "         #   article_topics = Node()\n",
    "            topics = re.findall(r'<D>(.*?)</D>', lt, re.DOTALL, overlapped=True)\n",
    "            # Make sure D tag does not included as part of the topic name\n",
    "            if(len(topics)==0):\n",
    "                # length is 0 when there is no topic\n",
    "                cntnotop=cntnotop+1\n",
    "            for l in topics:\n",
    "                # for every topic found in an article\n",
    "                if (find(trieTopics,l) == None):\n",
    "                    # check if the topic is already in the trie, and if not insert it with value 1\n",
    "                    insert(trieTopics, l, 1)\n",
    "          #          insert(article_topics, l, 1)\n",
    "           #     elif (find(article_topics, l) == None):\n",
    "            #        insert(article_topics, l, 1)\n",
    "             #       update(trieTopics, l, 1)\n",
    "                else:\n",
    "                    # its been found already in the trie so increase the value by 1\n",
    "                    update(trieTopics, l, 1)\n",
    "              #      update(article_topics, l, 1)\n",
    "                #article_topics.append(l)\n",
    "                listtopics.add(l)\n",
    "        \n",
    "        article_places = []\n",
    "        yPlace = re.findall(r'<PLACES>(.*?)</PLACES>', x[j], re.DOTALL, overlapped=True)\n",
    "        for k in range(0,len(yPlace)):\n",
    "            lt = yPlace[k]\n",
    "            places = re.findall(r'<D>(.*?)</D>', lt, re.DOTALL, overlapped=True)\n",
    "            if(len(places)==0):\n",
    "                cntnoplc=cntnoplc+1\n",
    "            for l in places:\n",
    "                if (find(trieLoc, l) == None):\n",
    "                    insert(trieLoc, l, 1)\n",
    "                else:\n",
    "                    update(trieLoc, l, 1)\n",
    "                article_places.append(l)\n",
    "                listplaces.add(l)\n",
    "\n",
    "        article_words = Node()        \n",
    "        yBody = re.findall(r'<BODY>(.*?)</BODY>', x[j], re.DOTALL, overlapped=True)\n",
    "        for b,word in enumerate(yBody):\n",
    "            # split the body into a bunch of different words\n",
    "            body = word.split()\n",
    "            body = [element.lower() for element in body] ; body            \n",
    "            for l in body:\n",
    "                if (find(WordCount, l) == None):\n",
    "                    insert(WordCount, l, 1)\n",
    "                    insert(article_words, l, 1)\n",
    "                elif (find(article_words, l) == None):\n",
    "                    insert(article_words, l, 1)\n",
    "                    update(WordCount, l, 1)\n",
    "                else:\n",
    "                    update(WordCount, l, 1)\n",
    "                    update(article_words, l, 1)\n",
    "                listwords.add(l)\n",
    "        #print (article_topics)\n",
    "        article_tries[articleCount] = [article_words]\n",
    "        articleCount += 1\n",
    "\n",
    "        \n",
    "# end of main for loop for all files\n",
    "\n",
    "# Print statements for the distinct list of topics, distinct list of places, and counts of topic-less and/or place-less \n",
    "# articles.  Although, we used set data structures to display the different keys here, it is easy to fetch values for keys \n",
    "# using a trie displayed below each.  Usage of sets was only done as part of \"developing our domain-specific knowledge\".\n",
    "listtopics = list(listtopics)\n",
    "listplaces = list(listplaces)\n",
    "listwords = list(listwords)\n",
    "#print(listtopics)\n",
    "#print(find_multiple(trieTopics, listtopics))\n",
    "#print(listplaces)\n",
    "#print(find_multiple(trieLoc, listplaces))\n",
    "#print(\"Data objects with no entries for topics: \" + str(cntnotop))\n",
    "#print(\"Data objects with no entries for places: \" + str(cntnoplc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tests for \"finds\" on the tries are shown below\n",
    "\n",
    "print (find(trieLoc, \"usa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(find(article_tries[10][0], 'a'))\n",
    "for i in range(len(article_tries)):\n",
    "    article_tries[i] = find_multiple(article_tries[i][0], listwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dtype(article_tries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (find_multiple(trieLoc, ['usa', 'west-germany']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (find(WordCount, 'agriculture'))\n",
    "print (find(WordCount, 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(listtopics) ) #120\n",
    "trieVals = find_multiple(trieTopics, listtopics)\n",
    "#print (trieVals)\n",
    "#topictrie[0] = listtopics\n",
    "#topictrie[1] = trieVals\n",
    "#print (topictrie[1])\n",
    "'''with open('output_trie_topics.csv', 'w') as csvfile:\n",
    "    fieldnames = ['topic', 'value']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(listtopics)):\n",
    "        writer.writerow({'topic': topictrie[0][i], 'value': topictrie[1][i]})'''\n",
    "#np.savetxt(\"output_trei_topics.csv\", topictrie, delimiter=\",\")\n",
    "print (len(find_multiple(article_tries[0][2], listwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN code\n",
    "\n",
    "db = DBSCAN(eps=100)\n",
    "\n",
    "\n",
    "find_mul"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
